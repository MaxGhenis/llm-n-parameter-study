{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1: Methodology\n",
    "\n",
    "## Research Design\n",
    "\n",
    "This study employs a controlled experimental design to compare the statistical properties of LLM outputs generated through two different methods:\n",
    "\n",
    "1. **Batch Generation**: Using the `n` parameter to generate multiple completions in a single API call\n",
    "2. **Sequential Generation**: Making separate API calls for each completion\n",
    "\n",
    "Our hypothesis is that these methods may produce statistically different distributions, violating the common assumption that LLM outputs are independent and identically distributed (i.i.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental Setup\n",
    "\n",
    "### Models Tested\n",
    "- OpenAI GPT-4o-mini\n",
    "- OpenAI GPT-4\n",
    "- Google Gemini Pro (using `candidateCount` parameter)\n",
    "\n",
    "### Test Prompts\n",
    "We use three categories of prompts to test different aspects of model behavior:\n",
    "\n",
    "1. **Random Number Generation**: \"Pick a random number between 1 and 100.\"\n",
    "2. **Classification Tasks**: Binary sentiment analysis\n",
    "3. **Creative Generation**: Short story beginnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from llm_n_parameter import NParameterExperiment, ExperimentConfig\n",
    "from llm_n_parameter import IndependenceAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Tests\n",
    "\n",
    "We employ multiple statistical tests to assess independence and distributional equivalence:\n",
    "\n",
    "### 1. Kolmogorov-Smirnov Test\n",
    "Tests whether two samples come from the same distribution.\n",
    "\n",
    "$$D_{n,m} = \\sup_x |F_{1,n}(x) - F_{2,m}(x)|$$\n",
    "\n",
    "where $F_{1,n}$ and $F_{2,m}$ are the empirical distribution functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_ks_test():\n",
    "    \"\"\"Demonstrate KS test on synthetic data.\"\"\"\n",
    "    from scipy.stats import ks_2samp\n",
    "    \n",
    "    # Same distribution\n",
    "    sample1 = np.random.normal(50, 10, 100)\n",
    "    sample2 = np.random.normal(50, 10, 100)\n",
    "    \n",
    "    ks_stat, p_value = ks_2samp(sample1, sample2)\n",
    "    print(f\"Same distribution: KS={ks_stat:.4f}, p={p_value:.4f}\")\n",
    "    \n",
    "    # Different distributions\n",
    "    sample3 = np.random.normal(55, 10, 100)\n",
    "    ks_stat, p_value = ks_2samp(sample1, sample3)\n",
    "    print(f\"Different distributions: KS={ks_stat:.4f}, p={p_value:.4f}\")\n",
    "\n",
    "demonstrate_ks_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Position Effects Analysis\n",
    "\n",
    "We test whether the position within a batch affects the output distribution. This is critical because prior research suggests potential within-batch dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_position_effects():\n",
    "    \"\"\"Visualize how position effects might manifest.\"\"\"\n",
    "    # Simulate data with position effects\n",
    "    n_batches = 20\n",
    "    batch_size = 5\n",
    "    \n",
    "    # Create data where position 0 tends higher\n",
    "    data = []\n",
    "    for batch in range(n_batches):\n",
    "        for position in range(batch_size):\n",
    "            # Add position-dependent bias\n",
    "            value = 50 + (2 - position) * 3 + np.random.normal(0, 5)\n",
    "            data.append({\n",
    "                'batch': batch,\n",
    "                'position': position,\n",
    "                'value': value\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Box plot by position\n",
    "    df.boxplot(column='value', by='position', ax=ax1)\n",
    "    ax1.set_title('Value Distribution by Position')\n",
    "    ax1.set_xlabel('Position in Batch')\n",
    "    ax1.set_ylabel('Value')\n",
    "    \n",
    "    # Mean value by position\n",
    "    position_means = df.groupby('position')['value'].mean()\n",
    "    ax2.plot(position_means.index, position_means.values, 'o-')\n",
    "    ax2.set_title('Mean Value by Position')\n",
    "    ax2.set_xlabel('Position in Batch')\n",
    "    ax2.set_ylabel('Mean Value')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_position = visualize_position_effects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This methodology allows us to:\n",
    "\n",
    "1. **Detect position effects**: Identify if outputs vary systematically by position within batch\n",
    "2. **Measure correlation**: Quantify the degree of within-batch dependence\n",
    "3. **Test distributional differences**: Determine if batch and sequential methods produce different distributions\n",
    "4. **Calculate research impact**: Estimate the effect on statistical power and confidence intervals\n",
    "\n",
    "The next chapter will apply this methodology to real LLM outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}