# LLM API Configuration
# Copy this file to .env and add your actual API keys

# OpenAI API Key (required for OpenAI experiments)
# Get yours at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Google AI API Key (required for Gemini experiments)  
# Get yours at: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Optional: Anthropic API Key (for future Claude experiments)
# Get yours at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Experiment Configuration
# Set to "mock" to use synthetic data instead of real API calls
EXPERIMENT_MODE=production

# Maximum number of API calls per experiment (cost control)
MAX_API_CALLS=100

# Default temperature for experiments
DEFAULT_TEMPERATURE=1.0

# Random seed for reproducibility
RANDOM_SEED=42

# Output Configuration
# Where to save experimental results
OUTPUT_DIR=data/experiments

# Logging level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Cache Configuration
# Enable caching of API responses
ENABLE_CACHE=true
CACHE_DIR=.cache/api_responses

# Cost Tracking
# Enable cost estimation and warnings
TRACK_COSTS=true
MAX_COST_USD=10.00

# Safety Configuration
# Dry run mode - log what would be done without making API calls
DRY_RUN=false